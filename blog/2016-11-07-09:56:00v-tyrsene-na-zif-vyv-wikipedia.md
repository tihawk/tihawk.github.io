---
slug: v-tyrsene-na-zif-vyv-wikipedia
title: В търсене на Зиф във Википедия
authors: kiroki
tags: [Наука, Science]
---

### Интродукция

Наскоро се заинтересувах от един интересен закон за разпределението на думите използвани в даден език, наречен законът на [Зиф](https://en.wikipedia.org/wiki/Zipf%27s_law). Според него честотата на употреба на думите в дадено произведение или просто смислена колекция следва експоненциален закон, т.е. броят на употреба на всяка следваща дума в списъка от използвани такива намаля експоненциално спрямо предишната. Последствие от това е, че горе долу във всяка такава колекция 80% от обема се състои от 20% от думите, принцип известен като Принципът на [Парето](https://en.wikipedia.org/wiki/Pareto_principle).

<!-- truncate -->

Причините за това се водят все още неизвестни, но си струва да се отбележи, че теории съществуват, и изникват от много различни клонове на науката - статистика, информационна теория, лингвистика, социология и т.н.

Един пример е решение заложено в принципа на най-малкото действие: говорещият се опитва да минимализира количеството думи, които използва, за да обясни нещо на слушащия. Слушащият би предпочел да чуе повече думи обясняващи ситуацията, минимализирайки усилието нужно да я разбере. Баланс между двете минимализации се намира там, където малко количество от думите  (20%) се използва в голяма част от времето (80%), и останалите 20% от обема думи се използва само по веднъж-дваж, за да даде конкретна представа за част от ситуацията.

Като цяло ми се струва, че за да се придобие по-ясна представа за това явление, човек трябва да се задълбочи в информационната теория. Там ентропията се дефинира като информация - колкото повече ентропия, толкова повече уникална информация, но в даден момент тази информация започва да губи ясно значение и смисъл, превръщайки се в бял шум. На един човек е необходим баланс между ненужна, повтаряща се информация (ниска ентропия) и прекалено много уникална информация, която не може да бъде разбрана и разчетена (максимална ентропия).

### Метод

След малко четене по въпроса, се заинтригувах да направя малък тест на този закон, извличайки стоте най-използвани думи в българската версия на Википедия, и правейки логаритмична графика на броя употреби на всяка дума спрямо мястото ѝ в списъка.

Целта на това графиката да е логаритмична, е че експоненциалните закономерности изглеждат като прави линии на такава графика, и е много лесно да се види, има ли такава закономерност или не.

Википедия е удобна за тази цел, тъй като те пазят бакъп на тяхната база данни, който е с открит достъп. Всички тези бакъпи могат да се намерят [тук](https://dumps.wikimedia.org/backup-index.html) За целта бях решил да напиша малко код, който да парсва от xml файла на бакъпа всички думи, и да ги добавя в речник заедно с броя употреби на дадената дума.

След бърз гугъл, открих че това вече е направено през далечната 2011-та година, и реших да се измързеля, и да взема наготово списъка със стоте най-използвани български думи във Википедия през 2011-та година от [този](http://nikolay.it/Blog/2011/08/%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7-%D0%BD%D0%B0-%D0%B1%D1%8A%D0%BB%D0%B3%D0%B0%D1%80%D1%81%D0%BA%D0%B8%D1%8F-%D0%B5%D0%B7%D0%B8%D0%BA-%D1%87%D1%80%D0%B5%D0%B7-Wikipedia/3)  пост.

Ако реша да задълбоча малко проучването на тези зависимости, със сигурност ще напиша собствен парсър, за да имам по-голям контрол над данните, но за целта този на Николай ми свърши идеална работа. Добре е да има хора заинтересовани в същите като теб странности.

Всичко което остава да се направи, е да се вземат данните и да се тикнат в графиката. За целта използвах [gnuplot](http://gnuplot.sourceforge.net/).

### Анализ на данните

Изборът на само 100-те най-популярни думи носи със себе си един определен бонус. В почти всички езици, първите 20-на думи (или повече) следват експоненциалната зависимост с по-малка точност, и допринасят за малко разнообразие в иначе скучната линейна графика.

Но дори в този случай генерално се вижда ясно експоненциалната зависимост между ранка на думата в нашия топ сто, и честотата ѝ на употреба.

![100-те най-използвани думи в българската Уикипедия](/content/images/2016/11/zipfs_law.png)

За пълнота, ето и самият списък думи който използвах за графиката, подредени по честост на поява, също като в графиката:

> на, и, в, потребител, е, от, за, се, пр, беседа, б, специални, приноси, с, да, г, категория, по, през, са, като, а, си, не, година, до, българия, шаблон, че, след, име, това, му, при, най, към, български, език, или, картинка, флаг, има, които, но, дата, място, той, софия, който, мъниче, град, н, роден, те, община, във, област, икона, време, години, македония, война, част, виж, век, население, което, село, която, със, много, сащ, описание, други, може, окръг, код, уикипедия, препратки, един, история, външни, също, американски, този, вид, всички, около, та, между, отбор, още, починал, карта, група, инфо, страна, селото, само, го

Както се вижда, освен очакваните най-използвани думи под формата на предлози и съюзи, се намират и някои интересни попълнения като "потребител". Тези напълно контекстно-зависими думи - които са тук само заради факта, че това са статии от википедия, по никакъв начин не нарушават закона на Зиф, и само допринасят за (не)очакваната линейна графика.

### Атомен анализ

Като бонус реших да направя подобна графика и с данните за употреба на буквите в същите тези статии:

![Анализ на буквите](/content/images/2016/11/bukvi.png)

Какво се случва тук? От една страна изглежда, че законът на Зиф не се следва в този случай, но от друга страна се случва нещо интересно, което прави тази графика дори по-любопитна от предишната.

Генерално все още изглежда сякаш честотата на употреба на букви следва някаква експоненциална закономерност, макар и не идеална, с очевадното изключение на последните две букви - ю и ь. Тези две букви изглежда доста се игнорират в българския език. Имайки предвид, че българският е сред най-твърдите славянски езици, ние наистина не намираме голяма употреба на буквата ь. Извън българския тя се използва за смекчаване на предходната съгласна, докато в българския се използва предимно в комбинация с о в ьо. В по-рядко използваните букви са и х, ф, ш, щ. Щ, подобно на ю е композитен звук, и е нормално да не се среща толкова често колкото останалите. Ф е пример за буква, която исторически е била добавена, за да акомодира гръцки думи в българския език. Естествено, с времето буквата е увеличила функцията си, но въпреки това не е исконно наш звук.

### Заключение

Като цяло тези данни могат да служат за много видове анализ. Убеден съм, че има хора които се занимават с това, но малкото ми свободно време и голямото ми любопитство ме доведе до писането на тези няколко реда по въпроса. Намирам за доста вероятно да продължа да разучавам какви интересни неща се крият в този ред на мисли, оглеждайки езика като малка част от информационната теория.